"""
Co-Builder Router for intent classification and action routing

Routes natural language messages to appropriate SBH actions:
- Build new modules (Phase 9)
- Provision existing modules (Phase 5-6)
- Resume projects (Phase 10)
- Status and health checks
- Operations and remediation (Phase 12)
- Growth intelligence (Phase 12)
"""

import re
import logging
import subprocess
import requests
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path

# Import LLM components
from src.ext.llm_client import LLMClient
from src.llm.providers import LLMProviderManager
from src.llm.schema import LLMMessage, MessageRole

logger = logging.getLogger(__name__)

class CoBuilderRouter:
    """Routes Co-Builder messages to appropriate SBH actions"""
    
    def __init__(self):
        logger.info("Initializing CoBuilderRouter...")
        
        # Initialize LLM components
        self.llm_client = None
        self.provider_manager = LLMProviderManager()
        logger.info("LLM provider manager initialized")
        
        # Model configuration with fallback
        self.primary_model = 'gpt-4o'  # Best model
        self.fallback_model = 'gpt-4o-mini'  # Reliable fallback
        self.emergency_model = 'gpt-3.5-turbo'  # Emergency fallback
        logger.info(f"Models configured: {self.primary_model}, {self.fallback_model}, {self.emergency_model}")
        
        # Initialize LLM client if possible
        try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
            logger.info("Attempting to initialize LLM client...")
            self.llm_client = LLMClient('system')
            logger.info("LLM client initialized successfully")
            
            # Test LLM client
            logger.info("Testing LLM client...")
            test_response = self.llm_client.run("test", model="gpt-4o-mini")
            logger.info(f"LLM test response: {test_response}")
            
        except Exception as e:
            logger.warning(f"Failed to initialize LLM client: {e}")
            logger.warning(f"LLM client error details: {type(e).__name__}: {str(e)}")
            self.llm_client = None
        
        self.build_keywords = [
            'build', 'create', 'add', 'generate', 'make', 'new module',
            'scaffold', 'set up', 'initialize'
        ]
        
        self.provision_keywords = [
            'provision', 'enable', 'install', 'activate', 'deploy',
            'set up', 'configure', 'start using'
        ]
        
        self.resume_keywords = [
            'resume', 'finish', 'complete', 'continue', 'pick up',
            'restore', 'recover', 'handoff', 'existing project', 'incomplete', 'finish building'
        ]
        
        self.gtm_keywords = [
            "trial", "subscribe", "cancel", "billing", "payment", "plan", "pricing", "upgrade", "downgrade"
        ]
        
        self.ops_keywords = [
            "fix", "migration", "reseed", "restart", "worker", "health", "status", "diagnose", "remediate"
        ]
        
        self.growth_keywords = [
            "growth", "metrics", "insights", "churn", "trial", "conversion", "revenue", "usage", "analytics"
        ]
        
        self.status_keywords = [
            "status", "health", "what", "how", "check", "overview", "summary",
            'status', 'health', 'what\'s installed', 'what is installed',
            'show modules', 'list modules', 'system status', 'health check'
        ]
    
    def route_message(self, message: str, tenant_id: str, dry_run: bool = False) -> Dict[str, Any]:
        """Route a message to the appropriate action handler with timeout protection"""
        message_lower = message.lower()
        
        # Classify intent
        intent = self._classify_intent(message_lower)
        
        logger.info(f"Routing message: '{message}' -> {intent}")
        
        try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
            # Route to appropriate action with timeout
            if intent == 'build':
                return self._handle_build(message, tenant_id, dry_run)
            elif intent == 'provision':
                return self._handle_provision(message, tenant_id, dry_run)
            elif intent == 'gtm':
                return self._handle_gtm(message, tenant_id, dry_run)
            elif intent == 'resume':
                return self._handle_resume(message, tenant_id, dry_run)
            elif intent == 'status':
                return self._get_system_status(tenant_id)
            elif intent == 'ops':
                return self._handle_ops(message, tenant_id, dry_run)
            elif intent == 'growth':
                return self._handle_growth(message, tenant_id, dry_run)
            else:
                return self._handle_unknown(message, tenant_id, dry_run, remaining_time)
                
        except Exception as e:
            logger.error(f"Error in route_message: {e}")
            # Return fallback response on any error
            return {
                "action_type": "error",
                "success": False,
                "response": f"❌ I encountered an error while processing your request. Please try again or ask for help with a specific task like building a module or checking system status.",
                "error": str(e)
            }
    
    def _generate_llm_response(self, message: str, context: str, tenant_id: str, remaining_time: float = None) -> str:
        """Generate LLM response with model fallback and timeout protection"""
        if not self.llm_client:
            return self._get_fallback_response(message, context)
        
        # Prepare system prompt
        system_prompt = f"""You are the SBH Co-Builder, an AI assistant that helps users build and manage systems.

Context: {context}

User message: {message}

Provide a helpful, actionable response. Be concise but thorough. If the user is asking about something you can't help with, suggest alternatives they can try.

Response format: Plain text, no markdown."""
        
        # Check deadline before processing
        if remaining_time is not None and remaining_time <= 0:
            logger.warning(f"LLM deadline exceeded (tenant: {tenant_id})")
            return "The request exceeded the processing time limit."
        
        # Try models in order of preference with timeout
        models_to_try = [self.primary_model, self.fallback_model, self.emergency_model]
        # Use remaining time or default timeout
        max_time_per_model = min(30, remaining_time) if remaining_time is not None else 30
        
            # Check deadline before each model attempt
            if remaining_time is not None:
                elapsed = time.monotonic() - start_time
                if elapsed >= remaining_time:
                    logger.warning(f"LLM deadline exceeded during model loop (tenant: {tenant_id})")
                    return "The request exceeded the processing time limit."
            
            try:
                start_time = time.time()
                remaining_ms = int(remaining_time * 1000) if remaining_time is not None else 30000
                logger.info(f"ask.model.start request_id=unknown model={model} remaining_ms={remaining_ms}")
                logger.info(f"Attempting LLM response with model: {model}")
                
                # Make LLM request with timeout
                response = self.llm_client.run(
                    prompt=system_prompt + "\n\nUser: " + message,
                    model=model,
                    temperature=0.7,
                    max_tokens=500
                )
                
                # Validate response structure
                if not isinstance(response, dict):
                    logger.warning(f"LLM response is not a dict: {type(response)}")
                    continue
                
                elapsed_time = time.time() - start_time
                elapsed_ms = int(elapsed_time * 1000)
                logger.info(f"ask.model.done request_id=unknown model={model} elapsed_ms={elapsed_ms}")
                
                # Check if response took too long
                if elapsed_time > max_time_per_model:
                    logger.warning(f"LLM response with {model} took too long ({elapsed_time:.2f}s), trying next model")
                    continue
                
                # Check if response is valid and has text
                if response.get("text") and not response.get("error"):
                    logger.info(f"LLM response successful with {model} in {elapsed_time:.2f}s")
                    
                    # Log successful response
                    from src.events import log_event
                    try:
                        log_event("llm_usage", tenant_id=tenant_id, payload={
                            "model": model,
                            "prompt_length": len(message),
                            "response_length": len(response.get("text", "")),
                            "elapsed_time": elapsed_time
                        })
                    except Exception as e:
                        logger.warning(f"Failed to log LLM usage: {e}")
                    
                    return response.get("text")
                
                logger.warning(f"LLM response with {model} is invalid or has error: {response}")
                continue
                
            except Exception as e:
                logger.error(f"Error with model {model}: {e}")
                continue
        
        # If all models fail, return fallback
        logger.error("All LLM models failed, using fallback response")
        return self._get_fallback_response(message, context)                
                # Make LLM request with timeout
                response = self.llm_client.run(
                    prompt=system_prompt + "\n\nUser: " + message,
                    model=model,
                    temperature=0.7,
                    max_tokens=500
                )
                
                # Validate response structure
                if not isinstance(response, dict):
                    logger.warning(f"LLM response is not a dict: {type(response)}")
                    continue
                
                elapsed_time = time.time() - start_time
                elapsed_ms = int(elapsed_time * 1000)
                logger.info(f"ask.model.done request_id=unknown model={model} elapsed_ms={elapsed_ms}")
                
                # Check if response took too long
                if elapsed_time > max_time_per_model:
                    logger.warning(f"LLM response with {model} took too long ({elapsed_time:.2f}s), trying next model")
                    continue
                
                # Check if response is valid and has text
                if isinstance(response, dict) and response.get('text') and not response.get('error'):
                    logger.info(f"LLM response successful with {model} in {elapsed_time:.2f}s")
                    
                    # Log successful response
                    from src.events import log_event
                    try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
                        log_event('cobuilder_llm_response', tenant_id=tenant_id, payload={
                            'model_used': model,
                            'response_time': elapsed_time,
                            'success': True
                        })
                    except Exception as e:
                        logger.warning("Analytics failure ignored: %s", e)
                    
                    return response['text']
                else:
                    error_msg = response.get('error', 'No text returned') if isinstance(response, dict) else f'Invalid response type: {type(response)}'
                    logger.warning(f"LLM response failed with {model}: {error_msg}")
                    
            except Exception as e:
                logger.warning(f"LLM request failed with {model}: {e}")
                continue
        
        # Add total timeout protection
        total_elapsed = time.time() - start_time
        if total_elapsed > 90:  # Total timeout after 90 seconds
            logger.error(f"Total LLM processing timeout after {total_elapsed:.2f}s")
            return self._get_fallback_response(message, context)
        
        # If all models fail, return fallback
        logger.error("All LLM models failed, using fallback response")
        return self._get_fallback_response(message, context)
    
    def _get_fallback_response(self, message: str, context: str) -> str:
        """Get fallback response when LLM is unavailable"""
        return f"""🤔 I'm having trouble processing your request right now, but I can still help with basic tasks.

Your message: "{message}"

Here are some things you can try:
• Build a new module: "Build a lightweight LMS with courses and progress tracking"
• Provision an existing module: "Provision CRM for tenant demo"
• Check system status: "What's the system status?"
• Resume a project: "Resume ./my-ecommerce-project"

If you need more advanced assistance, please try again in a moment."""
    
    def _classify_intent(self, message: str) -> str:
        """Classify the intent of a message"""
        # Check for build intent
        if any(keyword in message for keyword in self.build_keywords):
            return 'build'
        
        # Check for provision intent
        if any(keyword in message for keyword in self.provision_keywords):
            return 'provision'
        
        # Check for resume intent
        if any(keyword in message for keyword in self.resume_keywords):
            return 'resume'
        
        # Check for GTM intent
        if any(keyword in message for keyword in self.gtm_keywords):
            return "gtm"
        
        # Check for ops intent
        if any(keyword in message for keyword in self.ops_keywords):
            return "ops"
        
        # Check for growth intent
        if any(keyword in message for keyword in self.growth_keywords):
            return "growth"
        
        # Check for status intent
        if any(keyword in message for keyword in self.status_keywords):
            return 'status'
        
        return 'unknown'
    
    def _handle_build(self, message: str, tenant_id: str, dry_run: bool) -> Dict[str, Any]:
        """Handle build intent"""
        try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
            # Extract module type from message
            module_types = ['lms', 'crm', 'erp', 'helpdesk', 'analytics', 'ecommerce', 'blog', 'forum']
            module_type = None
            
            for mt in module_types:
                if mt in message.lower():
                    module_type = mt
                    break
            
            if not module_type:
                module_type = 'custom'
            
            # Call the build natural command
            cmd = ['python', '-m', 'src.cli', 'build', 'natural', '--spec', message]
            if dry_run:
                cmd.append('--dry-run')
            
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path.cwd())
            
            if result.returncode == 0:
                return {
                    "action_type": "build",
                    "success": True,
                    "response": f"✅ Module build completed successfully!\n{result.stdout}",
                    "module_type": module_type
                }
            else:
                return {
                    "action_type": "build",
                    "success": False,
                    "response": f"❌ Module build failed:\n{result.stderr}",
                    "module_type": module_type
                }
                
        except Exception as e:
            logger.error(f"Build action error: {e}")
            return {
                "action_type": "build",
                "success": False,
                "response": f"❌ Build action failed: {str(e)}"
            }
    
    def _handle_provision(self, message: str, tenant_id: str, dry_run: bool) -> Dict[str, Any]:
        """Handle provision intent"""
        try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
            # Extract module name from message
            module_names = ['flagship_crm', 'crm', 'erp_core', 'erp', 'lms']
            module_name = None
            
            for mn in module_names:
                if mn in message.lower():
                    module_name = mn
                    break
            
            if not module_name:
                return {
                    "action_type": "provision",
                    "success": False,
                    "response": "❌ Could not identify module to provision. Please specify: CRM, ERP, or LMS"
                }
            
            # Call marketplace provision
            response = requests.post(
                'http://127.0.0.1:5001/api/marketplace/provision',
                json={'module': module_name, 'tenant_id': tenant_id},
                headers={'X-Tenant-ID': tenant_id},
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                if data.get('success'):
                    return {
                        "action_type": "provision",
                        "success": True,
                        "response": f"✅ Successfully provisioned {module_name} for tenant {tenant_id}"
                    }
                else:
                    return {
                        "action_type": "provision",
                        "success": False,
                        "response": f"❌ Failed to provision {module_name}: {data.get('error', 'Unknown error')}"
                    }
            else:
                return {
                    "action_type": "provision",
                    "success": False,
                    "response": f"❌ Provision request failed with status {response.status_code}"
                }
                
        except Exception as e:
            logger.error(f"Provision action error: {e}")
            return {
                "action_type": "provision",
                "success": False,
                "response": f"❌ Provision action failed: {str(e)}"
            }
    
    def _handle_gtm(self, message: str, tenant_id: str, dry_run: bool) -> Dict[str, Any]:
        """Handle GTM intent"""
        try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
            # Extract action and module from message
            action = None
            module_name = None
            
            if any(word in message.lower() for word in ['trial', 'start trial']):
                action = 'trial'
            elif any(word in message.lower() for word in ['subscribe', 'subscription']):
                action = 'subscribe'
            elif any(word in message.lower() for word in ['cancel', 'cancellation']):
                action = 'cancel'
            
            # Extract module name
            module_names = ['flagship_crm', 'crm', 'erp_core', 'erp', 'lms']
            for mn in module_names:
                if mn in message.lower():
                    module_name = mn
                    break
            
            if not module_name:
                module_name = 'crm'  # Default to CRM
            
            # Execute GTM action
            if action == 'trial':
                response = requests.post(
                    'http://127.0.0.1:5001/api/marketplace/trial',
                    json={'tenant_id': tenant_id, 'module': module_name, 'plan': 'starter', 'days': 14},
                    headers={'X-Tenant-ID': tenant_id},
                    timeout=30
                )
            elif action == 'subscribe':
                response = requests.post(
                    'http://127.0.0.1:5001/api/marketplace/subscribe',
                    json={'tenant_id': tenant_id, 'module': module_name, 'plan': 'professional'},
                    headers={'X-Tenant-ID': tenant_id},
                    timeout=30
                )
            elif action == 'cancel':
                response = requests.post(
                    'http://127.0.0.1:5001/api/marketplace/cancel',
                    json={'tenant_id': tenant_id, 'module': module_name},
                    headers={'X-Tenant-ID': tenant_id},
                    timeout=30
                )
            else:
                return False
            
            return response.status_code in [200, 201]
        except Exception as e:
            logger.error(f"GTM action error: {e}")
            return False
    
    def _get_system_status(self, tenant_id: str) -> Dict[str, Any]:
        """Get system status"""
        try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
            response = requests.get(
                'http://127.0.0.1:5001/api/cobuilder/status',
                headers={'X-Tenant-ID': tenant_id},
                timeout=10
            )
            if response.status_code == 200:
                return response.json()['data']
            else:
                return {}
        except Exception as e:
            logger.error(f"Status error: {e}")
            return {}
    
    def _handle_ops(self, message: str, tenant_id: str, dry_run: bool) -> Dict[str, Any]:
        """Handle operations and health monitoring requests"""
        try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
            # Extract action and module from message
            action = None
            module = None
            
            if any(word in message.lower() for word in ["migration", "migrate"]):
                action = "migrate"
            elif any(word in message.lower() for word in ["reseed", "seed"]):
                action = "reseed"
            elif any(word in message.lower() for word in ["restart", "worker"]):
                action = "restart_worker"
            elif any(word in message.lower() for word in ["blueprint", "register"]):
                action = "reregister"
            
            # Extract module name
            module_names = ["flagship_crm", "crm", "erp_core", "erp", "lms"]
            for module_name in module_names:
                if module_name in message.lower():
                    module = module_name
                    break
            
            if not action:
                # Default to status check
                response = requests.get(
                    f'http://127.0.0.1:5001/api/ops/status?tenant_id={tenant_id}',
                    headers={'X-Tenant-ID': tenant_id},
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()['data']
                    return {
                        "action_type": "ops_status",
                        "success": True,
                        "response": f"🔍 Operations Status:\n• Overall: {data['status']}\n• Database: {data['checks']['database']['status']}\n• Migrations: {data['checks']['migrations']['status']}\n• Module Tables: {data['checks']['module_tables']['status']}"
                    }
                else:
                    return {
                        "action_type": "ops_status",
                        "success": True,
                        "response": "❌ Failed to get operations status"
                    }
            
            # Execute remediation action
            payload = {
                "action": action,
                "module": module,
                "tenant_id": tenant_id,
                "dry_run": dry_run
            }
            
            response = requests.post(
                'http://127.0.0.1:5001/api/ops/remediate',
                json=payload,
                headers={'X-Tenant-ID': tenant_id},
                timeout=60
            )
            
            if response.status_code == 200:
                data = response.json()['data']
                status_emoji = "✅" if data['status'] == 'success' else "⚠️" if data['status'] == 'dry_run' else "❌"
                return {
                    "action_type": "ops_remediate",
                    "success": True,
                    "response": f"{status_emoji} {data['action']}: {data['status']}\n{data['message']}"
                }
            else:
                return {
                    "action_type": "ops_remediate",
                    "success": False,
                    "response": f"❌ Remediation failed: {response.text}"
                }
                
        except Exception as e:
            logger.error(f"Ops action error: {e}")
            return {
                "action_type": "ops",
                "success": False,
                "response": f"❌ Operations error: {str(e)}"
            }
    
    def _handle_growth(self, message: str, tenant_id: str, dry_run: bool) -> Dict[str, Any]:
        """Handle growth intelligence requests"""
        try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
            # Determine what growth data to fetch
            if any(word in message.lower() for word in ["metrics", "data"]):
                # Get metrics for last 7 days
                from_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
                to_date = datetime.now().strftime('%Y-%m-%d')
                
                response = requests.get(
                    f'http://127.0.0.1:5001/api/growth/metrics?from={from_date}&to={to_date}&tenant_id={tenant_id}',
                    headers={'X-Tenant-ID': tenant_id},
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()['data']
                    return {
                        "action_type": "growth_metrics",
                        "success": True,
                        "response": f"📊 Growth Metrics (Last 7 Days):\n• Metrics collected: {data['count']}\n• Date range: {data['from_date']} to {data['to_date']}"
                    }
                else:
                    return {
                        "action_type": "growth_metrics",
                        "success": False,
                        "response": "❌ Failed to get growth metrics"
                    }
            else:
                # Get insights
                response = requests.get(
                    f'http://127.0.0.1:5001/api/growth/insights?tenant_id={tenant_id}',
                    headers={'X-Tenant-ID': tenant_id},
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()['data']
                    insights = data.get('conversion_rates', {})
                    alerts = data.get('alerts', [])
                    
                    response_text = "📈 Growth Insights:\n"
                    if insights.get('trial_to_paid'):
                        response_text += f"• Trial→Paid Conversion: {insights['trial_to_paid']}%\n"
                    
                    if alerts:
                        response_text += f"• Alerts: {len(alerts)} active\n"
                    
                    return {
                        "action_type": "growth_insights",
                        "success": True,
                        "response": response_text
                    }
                else:
                    return {
                        "action_type": "growth_insights",
                        "success": False,
                        "response": "❌ Failed to get growth insights"
                    }
                    
        except Exception as e:
            logger.error(f"Growth action error: {e}")
            return {
                "action_type": "growth",
                "success": False,
                "response": f"❌ Growth analysis error: {str(e)}"
            }
    
    def _handle_resume(self, message: str, tenant_id: str, dry_run: bool) -> Dict[str, Any]:
        """Handle resume intent"""
        try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
            # Extract project path from message
            project_path = None
            
            # Look for common project path patterns
            if './' in message or '/' in message:
                # Extract path after common phrases
                for phrase in ['resume', 'finish', 'complete', 'project']:
                    if phrase in message.lower():
                        start_idx = message.lower().find(phrase) + len(phrase)
                        path_part = message[start_idx:].strip()
                        if path_part.startswith('./') or path_part.startswith('/'):
                            project_path = path_part.split()[0]  # Take first word after path
                            break
            
            if not project_path:
                project_path = './my-project'  # Default path
            
            # Call project resume command
            cmd = ['python', '-m', 'src.cli', 'project', 'resume', project_path]
            if dry_run:
                cmd.append('--dry-run')
            
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path.cwd())
            
            if result.returncode == 0:
                return {
                    "action_type": "resume",
                    "success": True,
                    "response": f"✅ Project resume completed successfully!\n{result.stdout}",
                    "project_path": project_path
                }
            else:
                return {
                    "action_type": "resume",
                    "success": False,
                    "response": f"❌ Project resume failed:\n{result.stderr}",
                    "project_path": project_path
                }
                
        except Exception as e:
            logger.error(f"Resume action error: {e}")
            return {
                "action_type": "resume",
                "success": False,
                "response": f"❌ Resume action failed: {str(e)}"
            }
    
    def _handle_unknown(self, message: str, tenant_id: str, dry_run: bool) -> Dict[str, Any]:
        """Handle unknown intent with LLM response generation"""
        try:
            start_time = time.monotonic()
            # Check deadline before processing
            if remaining_time is not None and remaining_time <= 0:
                logger.warning(f"Request deadline exceeded in router (tenant: {tenant_id})")
                return {
                    "success": False,
                    "response": "The request exceeded the processing time limit.",
                    "action_type": "timeout",
                    "llm_generated": False
                }
            # Generate context for LLM
            context = "User asked about something not covered by standard SBH actions. Provide helpful guidance."
            
            # Check deadline before LLM call
            if remaining_time is not None:
                elapsed = time.monotonic() - start_time
                if elapsed >= remaining_time:
                    logger.warning(f"LLM deadline exceeded in _handle_unknown (tenant: {tenant_id})")
                    return {
                        "success": False,
                        "response": "The request exceeded the processing time limit.",
                        "action_type": "timeout",
                        "llm_generated": False
                    }
            
            # Generate LLM response
            llm_response = self._generate_llm_response(message, context, tenant_id, remaining_time)
            
            return {
                "action_type": "unknown",
                "success": True,
                "response": llm_response,
                "llm_generated": True
            }
            
        except Exception as e:
            logger.error(f"LLM response generation failed: {e}")
            logger.error(f"Error details: {type(e).__name__}: {str(e)}")
            # Fallback to static response
            return {
                "action_type": "unknown",
                "success": False,
                "response": f"🤔 I'm not sure how to handle: '{message}'\n\nTry asking me to:\n• Build a new module\n• Provision an existing module\n• Resume a project\n• Check system status\n• Fix system issues\n• Analyze growth metrics"
            }
